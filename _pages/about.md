---
permalink: /
title: "About Me"
excerpt: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am Kaixuan Huang (黄凯旋), a Ph.D. student in Electrical and Computer Engineering Department at Princeton University. I am fortunate to be advised by Professor [Mengdi Wang](https://mwang.princeton.edu/). Before that, I received B.S. in Mathematics and B.S. in Computer Science from Peking University. I was advised by Prof. Zhihua Zhang while doing undergraduate research. In 2019, I visited Georgia Tech as a research intern, supervised by Prof. [Tuo Zhao](https://www2.isye.gatech.edu/~tzhao80/). In 2020, I visited Tsinghua University as a research intern, supervised by Prof. [Longbo Huang](https://people.iiis.tsinghua.edu.cn/~huang/). I also worked closely with Prof. [Jason Lee](https://jasondlee88.github.io/).

 
My research interest is RL for foundation models (e.g., RLHF for diffusion models/language models) and foudation models for RL (LLM/VLM agents). I am open to possible cooperations or visiting opportunities. If you are interested, please contact me by email or [wechat](../files/wechat.jpg).


News
-----

- 10/2024: I will give a talk at INFORMS 2024 about CRISPR-GPT.
- 03/2024: I started my internship at Google DeepMind, working with Zheng Wen and Csaba Szepesvari.


Selected Publications
-----

- <font size="4"> A Theoretical Perspective for Speculative Decoding Algorithm </font>  <i> Ming Yin, Minshuo Chen, <b>Kaixuan Huang</b>, and Mengdi Wang </i>
<br/> NeurIPS 2024 <a href="https://arxiv.org/">[link]</a>


- <font size="4"> Latent Diffusion Models for Controllable RNA Sequence Generation </font>  <i> <b>Kaixuan Huang\*</b>, Yukang Yang\*, Kaidi Fu, Yanyi Chu, Le Cong, Mengdi Wang </i>
<br/> arXiv preprint <a href="https://arxiv.org/abs/2409.09828">[link]</a>


- <font size="4"> SORRY-Bench: Systematically Evaluating Large Language Model Safety Refusal Behaviors </font>  <i> Tinghao Xie, Xiangyu Qi, Yi Zeng, Yangsibo Huang, Udari Madhushani Sehwag, <b>Kaixuan Huang </b>, Luxi He, Boyi Wei, Dacheng Li, Ying Sheng, Ruoxi Jia, Bo Li, Kai Li, Danqi Chen, Peter Henderson, Prateek Mittal </i>
<br/> arXiv preprint <a href="https://arxiv.org/abs/2405.19524">[link]</a> <a href="https://sorry-bench.github.io/">[Website]</a> 


- <font size="4"> SpecDec++: Boosting Speculative Decoding via Adaptive Candidate Lengths </font>  <i> <b>Kaixuan Huang </b>, Xudong Guo, Mengdi Wang</i>
<br/> ICML 2024 workshop on Efficient Systems for Foundation Models (ES-FoMo) <a href="https://arxiv.org/abs/2405.19715">[link]</a> <a href="https://github.com/Kaffaljidhmah2/SpecDec_pp/">[Code]</a> 


- <font size="4"> AI Risk Management Should Incorporate Both Safety and Security </font>  <i> Xiangyu Qi, Yangsibo Huang, Yi Zeng, Edoardo Debenedetti, Jonas Geiping, Luxi He, <b> Kaixuan Huang </b>, Udari Madhushani, Vikash Sehwag, Weijia Shi, Boyi Wei, Tinghao Xie, Danqi Chen, Pin-Yu Chen, Jeffrey Ding, Ruoxi Jia, Jiaqi Ma, Arvind Narayanan, Weijie J Su, Mengdi Wang, Chaowei Xiao, Bo Li, Dawn Song, Peter Henderson, Prateek Mittal </i>
<br/> arXiv preprint <a href="https://arxiv.org/abs/2405.19524">[link]</a>

- <font size="4"> CRISPR-GPT: An LLM Agent for Automated Design of Gene-Editing Experiments </font>  <i> <b>Kaixuan Huang\*</b>, Yuanhao Qu\*, Henry Cousins, William A. Johnson, Di Yin, Mihir Shah, Denny Zhou, Russ Altman, Mengdi Wang, Le Cong</i>
<br/> arXiv preprint <a href="https://arxiv.org/abs/2404.18021">[link]</a>


- <font size="4"> Embodied LLM Agents Learn to Cooperate in Organized Teams </font>  <i> Xudong Guo, <b>Kaixuan Huang</b>, Jiale Liu, Wenhui Fan, Natalia Vélez, Qingyun Wu, Huazheng Wang, Thomas L. Griffiths, Mengdi Wang </i>
<br/> arXiv preprint <a href="https://arxiv.org/abs/2403.12482">[link]</a>

- <font size="4"> Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank Modifications </font>  <i> Boyi Wei\*, <b>Kaixuan Huang\*</b>, Yangsibo Huang\*, Tinghao Xie, Xiangyu Qi, Mengzhou Xia, Prateek Mittal, Mengdi Wang, Peter Henderson </i>
<br/> ICML 2024 <a href="https://arxiv.org/abs/2402.05162">[link]</a> <a href="https://github.com/boyiwei/alignment-attribution-code">[Code]</a> 

- <font size="4"> A 5' UTR Language Model for Decoding Untranslated Regions of mRNA and Function Predictions </font>  <i> Yanyi Chu\*, Dan Yu\*, Yupeng Li, <b>Kaixuan Huang</b>, Yue Shen, Le Cong, Jason Zhang, Mengdi Wang</i>
<br/> Nature Machine Intelligence (2024) <a href="https://www.nature.com/articles/s42256-024-00823-9">[link]</a> 

- <font size="4"> Visual Adversarial Examples Jailbreak Large Language Models </font>  <i> Xiangyu Qi\*, <b>Kaixuan Huang\*</b>, Ashwinee Panda, Peter Henderson, Mengdi Wang, Prateek Mittal </i>
<br/> AAAI 2024 (<b> Oral </b>) ICML2023 Adv ML workshop. (<b>Oral</b>) <a href="https://arxiv.org/abs/2306.13213">[link]</a> <a href="https://github.com/Unispac/Visual-Adversarial-Examples-Jailbreak-Large-Language-Models">[Code]</a> 

- <font size="4"> Scaling In-Context Demonstrations with Structured Attention </font>  <i> Tianle Cai\*, <b>Kaixuan Huang\*</b>, Jason D. Lee, Mengdi Wang </i>
<br/> ICML 2023 Workshop on Efficient Systems for Foundation Models.  <a href="https://arxiv.org/abs/2307.02690">[link]</a>

- <font size="4"> Reward-Directed Conditional Diffusion: Provable Distribution Estimation and Reward Improvement </font>  <i> Hui Yuan, <b>Kaixuan Huang</b>, Chengzhuo Ni, Minshuo Chen, Mengdi Wang</i>
<br/> In <i>Advances in Neural Information Processing Systems</i> (NeurIPS), 2023. <a href="https://arxiv.org/abs/2307.07055">[link]</a> <a href="https://github.com/Kaffaljidhmah2/RCGDM">[Code]</a> 

- <font size="4"> Score Approximation, Estimation and Distribution Recovery of Diffusion Models on Low-Dimensional Data </font>  <i> Minshuo Chen\*, <b>Kaixuan Huang\*</b>, Tuo Zhao, Mengdi Wang </i>
<br/> In <i>International Conference on Machine Learning</i> (ICML), 2023. <a href="https://arxiv.org/abs/2302.07194">[link]</a> 

- <font size="4"> Fast Federated Learning in the Presence of Arbitrary Device Unavailability </font>  <i> Xinran Gu\*, <b>Kaixuan Huang\*</b>, Jingzhao Zhang, Longbo Huang </i>
<br/> In <i>Advances in Neural Information Processing Systems</i> (NeurIPS), 2021. <a href="https://arxiv.org/abs/2106.04159">[link]</a> 

- <font size="4"> Why Do Deep Residual Networks Generalize Better than Deep Feedforward Networks? --- A Neural Tangent Kernel Perspective </font>
<i><b>Kaixuan Huang\*</b>, Yuqing Wang\*, Molei Tao, Tuo Zhao </i>
<br/> In <i>Advances in Neural Information Processing Systems</i> (NeurIPS), 2020. <a href="https://proceedings.neurips.cc//paper/2020/hash/1c336b8080f82bcc2cd2499b4c57261d-Abstract.html">[link]</a>

- <font size="4"> On the Convergence of FedAvg on Non-IID Data </font>
<i>Xiang Li\*, <b>Kaixuan Huang\*</b>, Wenhao Yang\*, Shusen Wang, Zhihua Zhang </i>
<br/> In <i>International Conference on Learning Representations</i> (ICLR), 2020. (<b>Oral Presentation</b>) <a href="https://openreview.net/forum?id=HJxNAnVtDS">[link]</a>


Misc.
-----

I love classical music and I practice playing piano 40 hours a day.

I implemented a tiny <a href="https://github.com/Kaffaljidhmah2/Arxiv-Recommender">[tool]</a> to help me filter out interesting daily arXiv papers.

My philosophical thoughts: (1) the interplay between network model structures and data intrinsic structures, and the generalization and extrapolation behaviors of the neural networks --- this resembles how humans' scientific discoveries match the real physical world, which has been investiaged by great philosophiers such as <a href="https://en.wikipedia.org/wiki/Critique_of_Pure_Reason">Immanuel Kant</a>. The forms of human perception, knowledge, reasoning, and decision-making have
also been studied by fields outside computer science.

<img src="https://ghchart.rshah.org/Kaffaljidhmah2" alt="Kaixuan's Github chart" />

Contact Info
------

Email: kaixuanh *AT* princeton *DOT* edu 

Wechat: [\[QR Code\]](../files/wechat.jpg)
